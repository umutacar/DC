\documentclass{course}
\title{Parallel and Sequential Algorithms}

% Course number must be unique in the database
\coursenumber{15210}

\semester{Spring2018}
\picture{./images/pont-neuf-le-soir.jpg}
\website{http://www.cs.cmu.edu/~15210}

% Provides book
% This must be provided
% The name should be relative to course number.
\providesbook{S18}

% Start counting chapters from 
% This is optional. Will start counting at 1.
\provideschapter{7}

15-210 aims to teach methods for designing, analyzing, and programming
sequential and parallel algorithms and data structures. The emphasis
is on teaching fundamental concepts applicable across a wide variety
of problem domains, and transferable across a reasonably broad set of
programming languages and computer architectures. This course also
includes a significant programming component in which students will
program concrete examples from domains such as engineering, scientific
computing, graphics, data mining, and information retrieval (web
search).

Unlike a traditional introduction to algorithms and data structures,
this course puts an emphasis on parallel thinking â€” i.e., thinking
about how algorithms can do multiple things at once instead of one at
a time. The course follows up on material learned in 15-122 and 15-150
but goes into significantly more depth on algorithmic issues. Concepts
covered in this class include:


\begin{book}
\title{Algorithm Design: Parallel and Sequential}
\label{15210-2016}
\unique{15210S18}
\authors{Umut A. Acar and Guy Blelloch}

\begin{chapter}[Sequences Chapter]
\label{ch:sequences}
% Number must be provided
\unique{3}

\picture{./images/gustav-puppy-stick.jpg}

\begin{section}[Sequences]
\label{sec:sequences}

A sequence is an ordered set, i.e., is a collection of elements that
are totally ordered. 
%
Computer scientists use sequence data grams such as arrays and
lists to represent many different sorts of data.
%

In this chapter, we specify a sequence abstract data type and consider
several cost specifications for it.
%
% In this book, we consider four different cost specifications for
% sequences, two based on arrays, one based on linked-lists, and based
% on trees.
%

%By thinking at this level of abstraction, we can use sequences without
%committing a particular implementation.  



\begin{unit}[Aggregation with  $\cd{scan}$]

\begin{gram}[The $\cd{scan}$ operation]
\label{gr:seq::scan-intro}
When we restrict ourselves to associative functions, the input-output
behavior of the function $\cd{reduce}$ can be defined in terms of the
$\cd{iterate}$. 
%
But the reverse is not true: $\cd{iterate}$ cannot always be defined
in terms of $\cd{reduce}$ because $\cd{iterate}$ can use the results
of intermediate states computed on the prefixes of the sequence,
whereas $\cd{reduce}$ cannot because such intermediate states are not
available.  
%
For example, in our parenthesis matching algorithm
(Algorithm~\ref{alg:seq::iterate::pmatch}), we used this property crucially by
defining our function to propagate a mismatched parenthesis forward in
the computation.  
%
We now describe a function called $\cd{scan}$ that
allows using the results of intermediate computations and also does so
in parallel.
\end{gram}

\begin{teachnote}[Operations in scan and iteration]
Note that scan still requires the function to be a binary operation
returning the same type as its argument, whereas iteration does not.
For example, the function for computing parenthesis matching does not
work as a scan operator.
\end{teachnote}

\begin{definition}[The function $\cd{scan}$]
\label{gr:seq::scan-intro}
The term ``scan'' refers to a computation that reduces every prefix of
a given sequence by repeatedly applying an associative binary
operation.  
%
The $\cd{scan}$ function has the type signature.
\[
\cd{scan}~(f: \alpha * \alpha \ra \alpha)~(id: \alpha)~(a: \sseq{\alpha})~:~(\sseq{\alpha} * \alpha),
\]
where $f$ is an associative function, $a$ is the sequence, and $id$ is
the left identity element of $f$.
%
The expression $\cd{scan}~f~a$ returns the ``sum'' with respect
to~$f$ of all prefixes of the input sequence~$a$.
%
For this reason, the $\cd{scan}$ operation is sometimes called the \defn{prefix sums} operation.
%


We define the semantics of $\cd{scan}$ inductively as follows.
\[
\cd{scan}~f~id~a
= 
\cseq{\cd{reduce}~f~id~a[0 \ldots i] : 0 \le i < \cseqlen{a}}
\]
\end{definition}

\begin{definition}[Inclusive Scan]
When computing the result for position~$i$, $\cd{scan}$ does not
include the element of the input sequence at that position.  It is
sometimes useful to do so.  To this end, we define $\cd{scanI}$ (``I''
stands for ``inclusive'').

We define the semantics of $\cd{scanI}$ inductively as follows.
\[
\cd{scanI}~f~id~a
= 
(
\cseq{\cd{reduce}~f~id~a[0 \ldots i] : 0 \le i \le \cseqlen{a}}
,
~\cd{reduce}~f~id~a
)
\]

\end{definition}

\begin{example}[Scan]
\parent{gr:seq::scan}
Consider the sequence $a = \cseq{0,1,2}$.
%
The prefixes of $a$ are  
\begin{itemize}
\item $\cseq{}$
\item $\cseq{0}$
\item $\cseq{0,1}$
\item $\cseq{0,1,2}.$
\end{itemize}
%
The prefixes of a sequence are all the subsequences of the sequence
that starts at its beginning. Empty sequence is a prefix of any
sequence.
%
The computation $\cd{scan}~\cd{+}~0~\cseq{0,1,2}$ can be written as
%
\[
\begin{array}{lclcl}
\cd{scan}~\cd{+}~0~\cseq{0,1,2}
& = & 
( & \cseqbb & \cd{reduce}~\cd{+}~0~\cseq{}, 
\\
& & & & \cd{reduce}~\cd{+}~0~\cseq{0}, 
\\
& & & & \cd{reduce}~\cd{+}~0~\cseq{0, 1} 
\\ 
& & & ~\cseqee, & 
\\
& & & & \cd{reduce}~\cd{+}~0~\cseq{0, 1, 2} 
\\
&  & )
\\
 & = & & & (\cseq{0, 0, 1}, 3).
\end{array}
\]
%
The computation $\cd{scanI}~\cd{+}~0~\cseq{0,1,2}$ can be written as
\[
\begin{array}{lclcl}
\cd{scanI}~\cd{+}~0~\cseq{0,1,2}
& = & 
%\left(
& \cseqbb & \cd{reduce}~\cd{+}~0~\cseq{0}, 
\\
& & & & \cd{reduce}~\cd{+}~0~\cseq{0, 1}, 
\\
& & & & \cd{reduce}~\cd{+}~0~\cseq{0, 1, 2,} 
\\
& & & \cseqee &
%\right)
\\
 & = & & & \cseq{0, 1, 3}.
\end{array}
\]
\end{example} 
%

\begin{gram}[Scan versus reduce]
begin{teachask}
Given that scan can be expressed just in terms of the operations that
we have already seen, why do we need it?
end{teachask}
%
Since \cd{scan} can be specified in terms of reduce, one might be
tempted to argue that it is redundant.
%
In fact, it is not: as we shall see, performing \cd{reduce} repeatedly
on every prefix is not work efficient.  
%
Remarkably \cd{scan} can be implemented by performing essentially the
same work and span of \cd{reduce}.
\end{gram}



\begin{example}[Copy scan]
\parent{gr:seq::scan}
  Scan is useful when we want pass information along the
  sequence. For example, suppose you have some ``marked'' elements
  that you would like to copy across to their right until they reach
  another marked element.
%
For example, suppose that we are given a sequence of type $\sseq{\tynat}$
consisting only of natural numbers and asked to return a sequence
of the same length where each element receives the previous positive
value.  For the example, for input $\cseq{0,~7,~0,~0,~3,~0}$, the
result should be $\cseq{0,~0,~7,~7,~7,~3}$.

Using a sequential loop or \cd{iterate} would be easy.  To solve
this problem using \cd{scan} we need a combining function $f$.  
%
Consider the function
%
\begin{lstlisting}
  skipZero $(x,y)$ = if $y > 0$ then $y$ else $x$.
\end{lstlisting}
%
%
The function passes its right argument if it is positive, otherwise it
passes on the left argument.
%

To be used in a scan it needs to be associative.  In particular we
need to show that  for all $x$, $y$ and $z$, we have
\[
\cd{skipZero}(x,\cd{skipZero}(y,z)) =
\cd{skipZero}(\cd{skipZero}(x,y),z).
\]
%
There are eight possibilities corresponding to each of $x$, $y$ and
$z$ being either positive or not.  
%
For the cases where $z$ is
positive, it is easy to verify that that either ordering returns $z$.
%
For the cases that $z = 0$ and $y$ is positive, it is likewise easy to
verify that both orderings give $y$.
%
Finally, for the cases that both $y = z = 0$ and $x$ is positive they
both return $x$, and for all being zero, the ordering returns zero.

To use \cd{skipZero} as part of the scan operation, we need to find
its left identity.  We can see that for any natural number $y$
\begin{lstlisting}
skipZero ($0$,$y$) =  $y$, 
\end{lstlisting}
and that for any natural number $x$
\begin{lstlisting}
skipZero ($x$,$0$) = $x$.
\end{lstlisting}
Thus $0$ is the left identity for \cd{skipZero}.
\end{example}

\begin{remark}[Reduce and scan]
Experience in parallel computing shows that \cd{reduce} and \cd{scan}
are powerful primitives that suffice to express many parallel
algorithms on sequences. 
%
In some ways this is not surprising, because the operations allow
using two important algorithm-design techniques: \cd{reduce} operation
allows expressing divide-and-conquer algorithms and
%
the \cd{scan} operation allows expressing a iterative algorithms.
\end{remark}

\end{unit}

\end{section}
\end{chapter}
\end{book}
